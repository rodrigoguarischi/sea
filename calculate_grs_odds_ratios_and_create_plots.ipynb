{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow used for:\n",
    "  1. Load metadata about GRSs used\n",
    "  1. Read phenotypic information and consolidate it with raw PGS scores from **apply_grs.ipynb**\n",
    "  1. Standardize raw scores and calculate Odds Ratios between case/controls\n",
    "  1. Generate visualization plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tkr\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os, glob\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "import glob\n",
    "import gzip\n",
    "import zepid\n",
    "from zepid.graphics import EffectMeasurePlot\n",
    "import matplotlib.lines as mlines\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import statistics\n",
    "from scipy.stats import iqr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1)** Load metadata about GRSs used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/labs/tassimes/rodrigoguarischi/projects/sea/apply_grs/pgs_reference_weights/\")\n",
    "\n",
    "# Load all key/values present on the header of PGS files into a dictionary\n",
    "pgs_metadata = {}\n",
    "for current_score_file in glob.glob( \"*.txt.gz\" ):\n",
    "    score_name = current_score_file.replace(\".txt.gz\",\"\")\n",
    "    pgs_metadata[score_name] = {}\n",
    "    with gzip.open( current_score_file,'rt') as f:\n",
    "        for line in f:\n",
    "            if( ( line.startswith(\"#\") ) & (not line.startswith(\"##\") ) ):\n",
    "                line = line.strip()\n",
    "                line = line.replace(\"#\", \"\")\n",
    "                key, value = line.split(\"=\")\n",
    "                pgs_metadata[score_name][key] = value\n",
    "    if( str( pgs_metadata[score_name][\"pgs_id\"] ).startswith(\"PGS\") ):\n",
    "        pgs_metadata[score_name][\"pgs_catalog_hyperlink\"] = \"https://www.pgscatalog.org/score/{0}/\".format(pgs_metadata[score_name][\"pgs_id\"])\n",
    "    else:\n",
    "        pgs_metadata[score_name][\"pgs_catalog_hyperlink\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2)** Read phenotypic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/labs/tassimes/rodrigoguarischi/projects/sea/\")\n",
    "\n",
    "# Read phenotypes and recode sex and race attributes\n",
    "sea_phenotypes = pd.read_table(\n",
    "    \"data_preparation_to_imputation/86679/NHLBI/SEA_Herrington/phs000349v1/p1/phenotype/phs000349.v1.pht002191.v1.p1.c1.SEA_Phase2_Subject_Phenotypes.GRU.txt\",\n",
    "    index_col=\"seaid\",\n",
    "    comment=\"#\")\n",
    "\n",
    "# Recode Sex and Race\n",
    "sea_phenotypes = sea_phenotypes.replace( {\n",
    "    \"sex\": { 1:\"male\", 2:\"female\" },\n",
    "    \"race\": { 1:\"white\", 2:\"black\" }\n",
    "    } )\n",
    "\n",
    "# Cast BMI values to integers\n",
    "sea_phenotypes = sea_phenotypes.assign( bmi=pd.to_numeric(sea_phenotypes[\"bmi\"], errors=\"coerce\") )\n",
    "\n",
    "# Drop unnecessary column\n",
    "sea_phenotypes = sea_phenotypes.drop(\"dbGaP SubjID\", axis = 1)\n",
    "\n",
    "# Print counts by race and sex and first lines from dataframe \n",
    "print( \"Statistics by subgroups:\" )\n",
    "print( sea_phenotypes.groupby([\"race\",\"sex\"])[\"sex\"].count(), \"\\n\" )\n",
    "\n",
    "# Print some summary statistics\n",
    "phenotype = \"cr\"\n",
    "\n",
    "for race in [ \"white\", \"black\"]:\n",
    "    print( \"For \" + race + \" (\" + str( len( sea_phenotypes[ sea_phenotypes[\"race\"] == race ] ) ) + \" subjects)\" )\n",
    "\n",
    "    age_values = sea_phenotypes[ sea_phenotypes[\"race\"] == race ][\"age\"]\n",
    "    print( \"  Age: mean {0:.1f}+-{1:.1f}; median {2:.1f} \".format( age_values.mean(), statistics.stdev( age_values ), age_values.median() ) )\n",
    "\n",
    "    # BMI dropning NA values (3 subjects)\n",
    "    bmi_values = sea_phenotypes[ sea_phenotypes[\"race\"] == race ][\"bmi\"].dropna()\n",
    "    print( \"  BMI: mean {0:.1f}+-{1:.1f}; median {2:.1f} \".format( bmi_values.mean(), statistics.stdev( bmi_values ), bmi_values.median() ) )\n",
    "\n",
    "    print( \"  # of males: \" + str( len( sea_phenotypes[ ( sea_phenotypes[\"race\"] == race ) & ( sea_phenotypes[\"sex\"] == \"male\" ) ] )  ) )\n",
    "    print( \"  # of subjects with RCA = 0: \" + str(len( sea_phenotypes[ ( sea_phenotypes[\"race\"] == race ) & ( sea_phenotypes[phenotype] == 0 ) ] ) ) )\n",
    "    \n",
    "    surface_area_values = sea_phenotypes[ ( sea_phenotypes[\"race\"] == race ) & ( sea_phenotypes[phenotype] > 0 ) ][phenotype]\n",
    "    print( \"  Of the subjects with RCA > 0, the surface area involvement was mean = {0:.1f}% (SD = {1:.1f}); median = {2:.1f}% (IQR = {3:.1f})\\n\".format(\n",
    "        surface_area_values.mean(),\n",
    "        statistics.stdev( surface_area_values ),\n",
    "        surface_area_values.median(),\n",
    "        iqr(surface_area_values)\n",
    "        ) )\n",
    "    \n",
    "\n",
    "# Print final dataframe\n",
    "sea_phenotypes\n",
    "\n",
    "# plt.rcParams['figure.dpi']= 150\n",
    "# sns.set_style('white')\n",
    "\n",
    "# sns.violinplot(\n",
    "#     x = \"race\",\n",
    "#     y = \"bmi_i\",\n",
    "#     hue = \"sex\",\n",
    "#     hue_order=['female','male'],\n",
    "#     split = True,\n",
    "#     bw=0.5,\n",
    "#     scale = \"count\",\n",
    "#     data = sea_dataset_full\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Load **PCA results** to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/labs/tassimes/rodrigoguarischi/projects/sea/pca_analysis/\")\n",
    "\n",
    "pca_results = {}\n",
    "\n",
    "pca_results[\"whites\"] = pd.read_table( \"pca_whites.eigenvec\", sep = \"\\t\" )\n",
    "pca_results[\"whites\"] = pca_results[\"whites\"].set_index(\"IID\")\n",
    "\n",
    "pca_results[\"blacks\"] = pd.read_table( \"pca_blacks.eigenvec\", sep = \"\\t\" )\n",
    "pca_results[\"blacks\"] = pca_results[\"blacks\"].set_index(\"IID\")\n",
    "\n",
    "pca_results[\"all\"] = pd.concat( [pca_results[\"whites\"], pca_results[\"blacks\"]], axis=0 ).drop(\"#FID\", axis = 1)\n",
    "\n",
    "sea_dataset_full = pd.concat( [sea_phenotypes, pca_results[\"all\"]], axis = 1 )\n",
    "sea_dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Consolidate raw **PGS scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files with raw scores of multiple GRSs\n",
    "\n",
    "li = []\n",
    "li.append(sea_dataset_full)\n",
    "\n",
    "os.chdir(\"/labs/tassimes/rodrigoguarischi/projects/sea/apply_grs/raw_scores_20220601/\")\n",
    "\n",
    "# Loop over info files and save info as a dictionary   \n",
    "scores_info_dict = {}\n",
    "for current_info_file in glob.glob( \"*.info.txt\" ):\n",
    "\n",
    "    # Parse filename to get info about GRSs.\n",
    "    # Format should be: <hrc|topmed>_<whites|blacks>_<8-digits_date>_multiGRS_<minr2_used>.info.txt\n",
    "    min_r2_used = os.path.basename( current_info_file ).split(\".\")[0].split(\"_\")[-1]\n",
    "    reference_panel_name = os.path.basename( current_info_file ).split(\"_\")[0]\n",
    "    race = os.path.basename( current_info_file ).split(\"_\")[1]\n",
    "    \n",
    "    f = open( current_info_file )\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Load metrics on a dictionary of dictionaries using panel, r2 and PGS name and each race as keys\n",
    "    for score_result in data:\n",
    "        key = \"_\".join( (reference_panel_name, min_r2_used, score_result[\"name\"]) )\n",
    "        \n",
    "        # If key doesn't exist yet in the dictionary, create it\n",
    "        if key not in scores_info_dict:\n",
    "            scores_info_dict[key] = {}\n",
    "            \n",
    "        scores_info_dict[key][race] = score_result\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# Loop over scores files, load all into memory and save it to list object 'li'    \n",
    "for current_score_file in glob.glob( \"*.scores.txt\" ):\n",
    "        \n",
    "    grs_results = pd.read_table( current_score_file, sep = \",\" )\n",
    "    grs_results[\"sample\"] = grs_results[\"sample\"].str.split(\"_\", expand = True)[0]\n",
    "    grs_results = grs_results.set_index(\"sample\")\n",
    "    min_r2_used = os.path.basename( current_score_file ).split(\".\")[0].split(\"_\")[-1]\n",
    "    reference_panel_name = os.path.basename( current_score_file ).split(\"_\")[0]\n",
    "        \n",
    "    # Add prefix to column names. Names should match pattern <hrc|topmed>_<threshold>_<scoreid>\n",
    "    grs_results = grs_results.add_prefix(reference_panel_name + \"_\" + min_r2_used + \"_\")\n",
    "\n",
    "    # Test if this set of scores already exists in li. \n",
    "    # If the other race was already loaded, append subjects to the dataframe. Otherwise, append dataframe to li\n",
    "    new_score_set = True\n",
    "    for i in range( len(li) ):\n",
    "        if( set( grs_results.columns ) == set( li[i].columns ) ):\n",
    "            li[i] = pd.concat( [li[i], grs_results], axis=0 )\n",
    "            new_score_set = False\n",
    "\n",
    "    if( new_score_set ):\n",
    "        li.append( grs_results )\n",
    "\n",
    "# Consolidate data into a dataframe and print first lines\n",
    "sea_dataset_full = pd.concat( li, axis=1 )\n",
    "sea_dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) Assign **case/control** cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign case/control classes to samples using top quartile rule splitting by sex\n",
    "\n",
    "# # Phenotype of interest\n",
    "# phenotype = \"cr\"\n",
    "\n",
    "# # Calculate thresholds for each race and sex\n",
    "# print( \"Thresholds to be used for case/control definition:\" )\n",
    "# thresholds = {}\n",
    "# for race in [\"white\", \"black\"]:\n",
    "#     for sex in [\"male\", \"female\"]:\n",
    "        \n",
    "#         # Define Q3 as threshold and save it in thresholds dictionary\n",
    "#         key = race + \"_\" + sex\n",
    "#         thresholds[ key ] = sea_dataset_full[ (( sea_dataset_full[\"race\"]==race ) & ( sea_dataset_full[\"sex\"]==sex ))  ][phenotype].quantile(0.75)\n",
    "        \n",
    "#         # Print values and warnings, if needed\n",
    "#         note = \"\"\n",
    "#         if( thresholds[ key ] == 0 ):\n",
    "#             note = \"(WARNING: This group has Q3 equals zero. Considering only non-zeros as CASE group!!)\"\n",
    "#         print( \" - {0} = {1:.4f} {2}\".format( key, thresholds[key], note ) )\n",
    "\n",
    "# # Add a new column called Case with all values equals to False\n",
    "# sea_dataset_full = sea_dataset_full.assign( Case=False )\n",
    "\n",
    "# # Identify subjects above threshold to assign them to group \"Case\"\n",
    "# for i in sea_dataset_full.index:\n",
    "\n",
    "#     sex = sea_dataset_full.loc[ i, \"sex\"]\n",
    "#     race = sea_dataset_full.loc[ i, \"race\"]\n",
    "#     key = race + \"_\" + sex\n",
    "    \n",
    "#     if( sea_dataset_full.loc[i, phenotype] > thresholds[ key ] ):\n",
    "#         sea_dataset_full.loc[i, \"Case\"] = True\n",
    "\n",
    "# # Print summary of Case/Controls for each subgroup\n",
    "# print( sea_dataset_full.groupby([\"race\",\"sex\",\"Case\"])[\"Case\"].count() )\n",
    "# sea_dataset_full\n",
    "\n",
    "### --------------------------------------------------------------------------------\n",
    "\n",
    "# Assign case/control classes using CR > 0 definition\n",
    "\n",
    "# Phenotype of interest\n",
    "phenotype = \"cr\"\n",
    "\n",
    "# Add a new column called Case with all values equals to False\n",
    "sea_dataset_full = sea_dataset_full.assign( Case=False )\n",
    "\n",
    "# Identify subjects above threshold to assign them to group \"Case\"\n",
    "for i in sea_dataset_full.index:\n",
    "    \n",
    "    if( sea_dataset_full.loc[i, phenotype] > 0 ):\n",
    "        sea_dataset_full.loc[i, \"Case\"] = True\n",
    "\n",
    "# Print summary of Case/Controls for each subgroup\n",
    "print( sea_dataset_full.groupby([\"race\",\"sex\",\"Case\"])[\"Case\"].count() )\n",
    "sea_dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6)** **Standardize** raw scores and calculate **Odds Ratios** between case/controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize raw scores and calculate OR\n",
    "\n",
    "li = []\n",
    "standardize_scores = []\n",
    "logit_models_dict = {}\n",
    "models_summaries = pd.DataFrame()\n",
    "\n",
    "# Get list of panels, thresholds and GRSs used from info dictonary\n",
    "reference_panels = set( [ key.split('_')[0] for key in scores_info_dict.keys() ] )\n",
    "thresholds = set( [ key.split('_')[1] for key in scores_info_dict.keys() ] )\n",
    "grss = set( [ key.split('_')[2] for key in scores_info_dict.keys() ] )\n",
    "\n",
    "# Normalize all scores with mean = 0 and SD = 1\n",
    "for race in [\"white\", \"black\"]:\n",
    "    \n",
    "    # Subset cohort between whites and blacks to run logistic regression individually\n",
    "    sea_dataset_subset = sea_dataset_full[ sea_dataset_full[\"race\"] == race ]\n",
    "\n",
    "    # Create a dependent variable named \"Case_recoded\" based on column \"Case\", conding it as 0 and 1 to fit glm\n",
    "    sea_dataset_subset = sea_dataset_subset.assign( Case_recoded=sea_dataset_subset[\"Case\"].replace(True, 1).replace(False, 0) )\n",
    "    \n",
    "    for reference_panel_id in reference_panels:\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "\n",
    "            for grs in grss:\n",
    "\n",
    "                raw_score_name = \"_\".join( (reference_panel_id, threshold, grs) )\n",
    "                standardize_score_name = \"_\".join( (race, reference_panel_id, threshold, grs) )\n",
    "                standardize_scores.append(standardize_score_name)\n",
    "        \n",
    "                # Standardize raw scores using method scale\n",
    "                sea_dataset_subset[ standardize_score_name ] = preprocessing.scale( sea_dataset_subset[ raw_score_name ] )\n",
    "        \n",
    "                # Fit a logistic model using standardize scores and save it on dictionary \n",
    "                logit_models_dict[ standardize_score_name ] = sm.formula.glm(\n",
    "                    \"Case_recoded ~ \" + standardize_score_name + \" + age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\",\n",
    "                    # \"Case_recoded ~ \" + standardize_score_name + \" + age + sex + bmi + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\",\n",
    "                    family=sm.families.Binomial(),\n",
    "                    data=sea_dataset_subset).fit()\n",
    "\n",
    "                # Create dictonary with scores performances\n",
    "                model_summary_series = {\n",
    "                        \"model_ref\": raw_score_name,\n",
    "                        \"race\": race,\n",
    "                        \"reference_panel\": reference_panel_id,\n",
    "                        \"threshold\": threshold,\n",
    "                        \"GRS\": grs,\n",
    "                        \"odds_ratio\": np.exp( logit_models_dict[ standardize_score_name ].params )[ standardize_score_name ],\n",
    "                        \"score_pvalue\": logit_models_dict[ standardize_score_name ].pvalues[ standardize_score_name ],\n",
    "                        \"conf_interval_lower\": np.exp( logit_models_dict[ standardize_score_name ].conf_int()[0][ standardize_score_name ] ),\n",
    "                        \"conf_interval_upper\": np.exp( logit_models_dict[ standardize_score_name ].conf_int()[1][ standardize_score_name ] )\n",
    "                    }\n",
    "                # Add additional info from info files (coverage, etc)\n",
    "                model_summary_series.update( scores_info_dict[raw_score_name][race + \"s\"] )\n",
    "                \n",
    "                # Add metadata about the GRSs to the output\n",
    "                model_summary_series.update( pgs_metadata[grs] )\n",
    "                \n",
    "                # Transform dictionary on a pandas Series and name it as <standardize_score_name>\n",
    "                model_summary_series = pd.Series(\n",
    "                    data=model_summary_series,\n",
    "                    name=standardize_score_name\n",
    "                )\n",
    "                                \n",
    "                li.append(model_summary_series)\n",
    "                     \n",
    "# Concatenate results for all models tested and transpose object to make visualization easier \n",
    "models_summaries = pd.concat( li, axis=1 ).transpose().sort_values(\"odds_ratio\", ascending=False)\n",
    "\n",
    "# Move trait_mapped column to first position to facilitate analysis of excel results\n",
    "columns_order = models_summaries.columns.drop(\"trait_mapped\").tolist()\n",
    "columns_order.insert(0,\"trait_mapped\")\n",
    "models_summaries = models_summaries.reindex(columns=columns_order, copy=False)\n",
    "models_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7)** Export dataframe with summaries as a **xls** file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe with summaries on a xls file on the exports folder\n",
    "\n",
    "writer = pd.ExcelWriter(\n",
    "    path = \"/labs/tassimes/rodrigoguarischi/projects/sea/exports/SEA_models_summary.xls\",\n",
    "    engine = 'xlsxwriter'\n",
    "    )\n",
    "\n",
    "models_summaries.to_excel(writer, sheet_name='models_summary')\n",
    "# models_summaries_interaction.to_excel(writer, sheet_name='models_summary')\n",
    "\n",
    "# Get access to the workbook and sheet\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets['models_summary']\n",
    "\n",
    "# Automatically add filters to columns\n",
    "worksheet.autofilter( \"A1:AH{0}\".format(len( models_summaries.index ) + 1) )\n",
    "\n",
    "# Add a percent format with 2 decimal points\n",
    "percent_fmt = workbook.add_format({'num_format': '0.00%', 'align': 'left'})\n",
    "\n",
    "# Add a left-alignment format\n",
    "left_alignment_fmt = workbook.add_format({'align': 'left'})\n",
    "\n",
    "# Format the columns by width and include number formats\n",
    "default_column_width = 11\n",
    "worksheet.set_column('A:A', 35, left_alignment_fmt)                         # Model full name\n",
    "worksheet.set_column('B:B', 45, left_alignment_fmt)                         # Trait mapped\n",
    "worksheet.set_column('C:C', 30, left_alignment_fmt)                         # Model ref\n",
    "worksheet.set_column('D:O', default_column_width, left_alignment_fmt)     \n",
    "worksheet.set_column('P:P', default_column_width, percent_fmt)              # Coverage\n",
    "worksheet.set_column('Q:AF', default_column_width, left_alignment_fmt)\n",
    "worksheet.set_column('AG:AG', 70, left_alignment_fmt)                       # Citation\n",
    "worksheet.set_column('AH:AH', 40, left_alignment_fmt)                       # PGS catalog link\n",
    "worksheet.set_column('AI:AI', default_column_width, left_alignment_fmt)     # License\n",
    "\n",
    "# Transform cells on column AH on hyperlinks\n",
    "for model_index in range(0, len(models_summaries)):\n",
    "\n",
    "    # Skip one line for the header +1 because excel location is 1-based\n",
    "    row_number = model_index + 2\n",
    "    model_index_name = models_summaries.index[model_index]\n",
    "    \n",
    "    # Get text to transform it to URL\n",
    "    hyperlink = models_summaries.loc[model_index_name,\"pgs_catalog_hyperlink\"]\n",
    "    \n",
    "    # write text as hyperlink\n",
    "    worksheet.write_url( \"AH\" + str(row_number), hyperlink)\n",
    "\n",
    "## Add colors to cells of coverage labels to easy visualization\n",
    "\n",
    "# Create a red, yellow and green fills with dark text\n",
    "red_format = workbook.add_format({'bg_color':   '#FFC7CE', 'font_color': '#9C0006'})\n",
    "yellow_format = workbook.add_format({'bg_color':   '#FFEB9C', 'font_color': '#9C6500'})\n",
    "green_format = workbook.add_format({'bg_color':   '#C6EFCE', 'font_color': '#006100'})\n",
    "\n",
    "# Get location of coverage label cells\n",
    "cells_location = 'W1:W' + str( len(models_summaries) + 1)\n",
    "\n",
    "worksheet.conditional_format( cells_location, {'type': 'cell', 'criteria': 'equal to', 'value': '\"high\"', 'format': green_format} )\n",
    "worksheet.conditional_format( cells_location, {'type': 'cell', 'criteria': 'equal to', 'value': '\"medium\"', 'format': yellow_format} )\n",
    "worksheet.conditional_format( cells_location, {'type': 'cell', 'criteria': 'equal to', 'value': '\"low\"', 'format': red_format} )\n",
    "worksheet.conditional_format( cells_location, {'type': 'cell', 'criteria': 'equal to', 'value': '\"zero\"', 'format': red_format} )\n",
    "\n",
    "# Save modifications\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot selected scores segregrating cohort in whites and blacks \n",
    "\n",
    "# Set image resolution and background\n",
    "from shutil import which\n",
    "\n",
    "plt.rcParams['figure.dpi']= 150\n",
    "sns.set_style('white')\n",
    "\n",
    "# Function to return a subset of models that will be used on the forest plot\n",
    "def get_models_subset(race, reference_panel_id, grs_subset, threshold ):\n",
    "    \n",
    "    # Get only subset of lines that meet the criteria\n",
    "    models_subset = models_summaries[ (models_summaries[\"race\"] == race) & (models_summaries[\"reference_panel\"] == reference_panel_id) & (models_summaries[\"GRS\"].isin( grs_subset) ) & (models_summaries[\"threshold\"] == threshold )]\n",
    "    models_subset = models_subset.sort_values(\"odds_ratio\", ascending=False)\n",
    "    \n",
    "    return( models_subset )\n",
    "\n",
    "# Define acronym and classes of selected scores\n",
    "grs_subset_and_info = {\n",
    "    \"PGS000018\": [\"CAD      metaGRS    1,745,179\", \"CAD\"], \n",
    "    \"PGS000889\": [\" LDL          P+T           9,009    \", \"Dyslipidemia\"], \n",
    "    \"PGS002133\": [\"Fat %     LDpred2        995,419\", \"Adiposity\"],\n",
    "    \"PGS001351\": [\"  Ins         PRS-CS     1,025,098\", \"Dysglycemia\"], \n",
    "    \"PGS002161\": [\"BMI      LDpred2        990,022 \", \"Adiposity\"], \n",
    "    \"PGS000667\": [\"Lp(a)          GWS            43      \", \"Dyslipidemia\"], \n",
    "    \"PGS002197\": [\" Trig       LDpred2       731,035 \", \"Dyslipidemia\"], \n",
    "    \"PGS002026\": [\" T2D      LDpred2       830,783 \", \"Dysglycemia\"], \n",
    "    \"PGS002009\": [\" SBP        P. reg.          68,449  \", \"Hypertension\"]\n",
    "    # \"wGRS49\": [\"CAD  \", \"CAD\"], \n",
    "    # \"TEMprsCatherineWhites\": [\"CAD  \", \"CAD\"], \n",
    "    # \"PGS002150\": [\" LDL  \", \"Dyslipidemia\"], \n",
    "    # \"PGS001933\": [\" LDL  \", \"Dyslipidemia\"]\n",
    "    # \"PGS002114\": [\"DBP\", \"Hypertension\"]\n",
    "    }\n",
    "class_to_color = {\n",
    "    \"CAD\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[19],\n",
    "    \"Adiposity\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[32],\n",
    "    \"Dysglycemia\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[13],\n",
    "    \"Dyslipidemia\": sns.color_palette( n_colors=40, palette=\"Dark2\" )[4],\n",
    "    \"Hypertension\": sns.color_palette( n_colors=10, palette=\"Blues\" )[6]\n",
    "    }\n",
    "\n",
    "for race in ['white', \"black\"]:\n",
    "\n",
    "    # Subset based on criterias and save to a new dataframe\n",
    "    models_subset = get_models_subset( race, \"topmed\", grs_subset_and_info.keys(), \"r0\")\n",
    "    \n",
    "    # Assign classes and colors to each score\n",
    "    models_subset = models_subset.assign( acronym=[ grs_subset_and_info[ elem ][0] for elem in models_subset[\"GRS\"].to_list() ] )\n",
    "    models_subset = models_subset.assign( grs_class=[ grs_subset_and_info[ elem ][1] for elem in models_subset[\"GRS\"].to_list() ] )\n",
    "    models_subset = models_subset.assign( color=[ class_to_color[ elem ] for elem in models_subset[\"grs_class\"].to_list() ] )\n",
    "    \n",
    "    # Test p-values to see if they survive to multiple testing correction (FDR)\n",
    "    fdr_result = fdrcorrection( models_subset[\"score_pvalue\"].to_list() )\n",
    "    models_subset = models_subset.assign( adjusted_p=fdr_result[1] )\n",
    "    models_subset = models_subset.assign( fdr_significant=fdr_result[0] )\n",
    "\n",
    "    # # Print p-values/q-values\n",
    "    # print(\"Race: \" + race )\n",
    "    # print(\"p-values:\\n\" + \"\\n\".join(map(str, models_subset[\"score_pvalue\"].to_list()) ) )\n",
    "    # print(\"\\nq-values:\\n\" + \"\\n\".join(map(str, fdr_result[1] ) ) + \"\\n\")\n",
    "    \n",
    "    # Create plot\n",
    "    p = EffectMeasurePlot(\n",
    "        label=[ \"{0}     {1}       {2:.3f}{3}\".format(row[\"GRS\"], row[\"acronym\"], row[\"score_pvalue\"], \"*\" if( row[\"fdr_significant\"] ) else \"  \" ) for index, row in models_subset.iterrows() ], \n",
    "        # label=[ \"{0}    {1:.2e}{2}\".format(row[\"pgs_name\"], row[\"score_pvalue\"], \"*\" if( row[\"fdr_significant\"] ) else \"  \" ) for index, row in models_subset.iterrows() ], \n",
    "        effect_measure=[ \"{0:.2f}\".format(row[\"odds_ratio\"]) for index, row in models_subset.iterrows() ],\n",
    "        lcl=[ \"{0:.2f}\".format(row[\"conf_interval_lower\"]) for index, row in models_subset.iterrows() ],\n",
    "        ucl=[ \"{0:.2f}\".format(row[\"conf_interval_upper\"]) for index, row in models_subset.iterrows() ]\n",
    "        )\n",
    "    # Adjust axis, labels, titles and frame\n",
    "    p.labels(effectmeasure='OR', scale='log')\n",
    "    p.colors(pointshape=\"D\", pointcolor=models_subset[\"color\"], errorbarcolor=models_subset[\"color\"] )\n",
    "    ax=p.plot(figsize=(7,3), t_adjuster=0.05, min_value=0.5, max_value=2)    \n",
    "    plt.suptitle(\" PGS ID   Trait  Method  N variants  p-value   \", x=-0.14, y=0.90, fontweight=\"bold\")\n",
    "    number_of_cases = len( sea_dataset_full[ ( sea_dataset_full[\"race\"] == race ) & ( sea_dataset_full[\"Case\"] == True ) ] )\n",
    "    number_of_controls = len( sea_dataset_full[ ( sea_dataset_full[\"race\"] == race ) & ( sea_dataset_full[\"Case\"] == False ) ] )\n",
    "    plt.title(\"{0} ({1} cases, {2} controls)         Odds Ratio per SD increase\".format(race.capitalize(), number_of_cases, number_of_controls), loc=\"right\",x=1.2, y=1.02)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.tick_params( axis='x', which=\"minor\", bottom=False )\n",
    "        \n",
    "# Add legend\n",
    "trait_handles = []\n",
    "for grs_class in sorted( set( models_subset[ \"grs_class\" ] )  ):\n",
    "    trait_handles.append( mlines.Line2D([], [], label=grs_class, color=class_to_color[grs_class], marker='_', markersize=15) )\n",
    "ax.legend(handles=trait_handles, loc=(-0.5, -0.3), shadow=False, borderpad=0.6, ncol=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram plots with raw scores\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(12,5))\n",
    "\n",
    "for score in [\"topmed_r0_PGS000018\", \"topmed_r0_PGS000889\"]:\n",
    "\n",
    "    sns.histplot(\n",
    "        x = score,\n",
    "        hue = \"race\",\n",
    "        kde=True,\n",
    "        data = sea_dataset_full,\n",
    "        ax = ax1 if score == \"topmed_r0_PGS000018\" else ax2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot score quantiles using % of cohort where Case = True\n",
    "\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'Q_%s' % n\n",
    "    return percentile_\n",
    "\n",
    "def cases_percentage(x):\n",
    "    frac = sum(x)/len(x)\n",
    "    return frac\n",
    "\n",
    "def show_values(axs, orient=\"v\", space=.01):\n",
    "    def _single(ax):\n",
    "        if orient == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n",
    "                value = '{:.1f}'.format(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif orient == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)\n",
    "                value = '{:.1f}'.format(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _single(ax)\n",
    "    else:\n",
    "        _single(axs)\n",
    "\n",
    "# Set image resolution and background\n",
    "plt.rcParams['figure.dpi']= 150\n",
    "sns.set_style('white')\n",
    "\n",
    "# Create a 2 panel plot\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(12,5))\n",
    "\n",
    "# Define for which race subgroup to make barplots\n",
    "race = \"white\"\n",
    "\n",
    "## Plot score quantiles using % of cohort where Case = True\n",
    "\n",
    "# Subset cohort to whites only\n",
    "# sea_dataset_subset = sea_dataset_full\n",
    "sea_dataset_subset = sea_dataset_full[ sea_dataset_full[\"race\"] == race ]\n",
    "\n",
    "# Split data on non equally-sized quantiles (20-60-20)\n",
    "quantile_labels = [\"Q1\", \"Q2-Q4\", \"Q5\"]\n",
    "sea_dataset_subset = sea_dataset_subset.assign( CAD=pd.qcut(sea_dataset_subset[\"topmed_r0_PGS000018\"], [0,0.2,0.8,1], labels=quantile_labels) )\n",
    "sea_dataset_subset = sea_dataset_subset.assign( LDL=pd.qcut(sea_dataset_subset[\"topmed_r0_PGS000889\"], [0,0.2,0.8,1], labels=quantile_labels) )\n",
    "\n",
    "cases_quantiles = pd.concat( [\n",
    "        sea_dataset_subset.groupby([\"CAD\"])[\"Case\"].agg( [ \"count\", \"sum\", cases_percentage ] ).assign( score=\"CAD\", quantile=quantile_labels ),\n",
    "        sea_dataset_subset.groupby([\"LDL\"])[\"Case\"].agg( [ \"count\", \"sum\", cases_percentage ] ).assign( score=\"LDL\", quantile=quantile_labels )\n",
    "    ] )\n",
    "\n",
    "# Transform value in percentage\n",
    "cases_quantiles[\"cases_percentage\"] = cases_quantiles[\"cases_percentage\"] * 100\n",
    "\n",
    "# Print some basic statistics\n",
    "print( cases_quantiles )\n",
    "    \n",
    "# Plot \n",
    "p = sns.barplot(\n",
    "    x = \"quantile\",\n",
    "    y = \"cases_percentage\",\n",
    "    hue = \"score\",\n",
    "    ci = None,\n",
    "    palette = {\n",
    "        \"CAD\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[19],\n",
    "        \"LDL\": sns.color_palette( n_colors=40, palette=\"Dark2\" )[4]\n",
    "    },\n",
    "    data = cases_quantiles,\n",
    "    ax = ax1\n",
    "    )\n",
    "\n",
    "# Change axis labels\n",
    "p.set( xlabel = \"Score quintiles\", ylabel = \"Prevalence of raised coronary lesions (%)\" )\n",
    "\n",
    "# Display value on top of barplots\n",
    "show_values(p)\n",
    " \n",
    "## Plot score quantiles using median % of surface with RC (only CR+ cases)\n",
    "\n",
    "# Subset cohort to whites only\n",
    "# sea_dataset_subset = sea_dataset_full\n",
    "sea_dataset_subset = sea_dataset_full[ ( sea_dataset_full[\"race\"] == race ) & (sea_dataset_full[\"Case\"] == True) ]\n",
    "\n",
    "# Split data on non equally-sized quantiles (20-60-20)\n",
    "quantile_labels = [\"Q1\", \"Q2-Q4\", \"Q5\"]\n",
    "sea_dataset_subset = sea_dataset_subset.assign( CAD=pd.qcut(sea_dataset_subset[\"topmed_r0_PGS000018\"], [0,0.2,0.8,1], labels=quantile_labels) )\n",
    "sea_dataset_subset = sea_dataset_subset.assign( LDL=pd.qcut(sea_dataset_subset[\"topmed_r0_PGS000889\"], [0,0.2,0.8,1], labels=quantile_labels) )\n",
    "\n",
    "# Print some basic statistics\n",
    "y_variable = \"cr\"\n",
    "print( sea_dataset_subset.groupby( [ \"race\", \"CAD\" ] )[y_variable].agg( [ \"count\", \"min\", percentile(25), \"median\", percentile(75), \"mean\", \"max\",  ] ).round(2) )\n",
    "print( sea_dataset_subset.groupby( [ \"race\", \"LDL\" ] )[y_variable].agg( [ \"count\", \"min\", percentile(25), \"median\", percentile(75), \"mean\", \"max\",  ] ).round(2) )\n",
    "\n",
    "# Generate barplot of score quantiles using median % of surface with RC\n",
    "p = sns.barplot(\n",
    "    x = 'value',\n",
    "    y = y_variable,\n",
    "    hue = 'variable',\n",
    "    ci = None,\n",
    "    estimator=np.median,\n",
    "    order = quantile_labels,\n",
    "    palette = {\n",
    "        \"CAD\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[19],\n",
    "        \"LDL\": sns.color_palette( n_colors=40, palette=\"Dark2\" )[4]\n",
    "        },\n",
    "    data = pd.melt( sea_dataset_subset, id_vars=[y_variable], value_vars=['CAD', 'LDL'], ignore_index=False ),\n",
    "    ax = ax2\n",
    "    )\n",
    "\n",
    "# Change axis labels and ranges\n",
    "# p.set( xlabel=\"Score quintiles\", ylabel=\"Mean surface area involvement (%)\", ylim=(0,18) )\n",
    "p.set( xlabel=\"Score quintiles\", ylabel=\"Median surface area involvement (%)\", ylim=(0,8) )\n",
    "\n",
    "# Display value on top of barplots\n",
    "show_values(p)\n",
    "\n",
    "# Add a single legend for both panels\n",
    "trait_handles = []\n",
    "trait_handles.append( mlines.Line2D([], [], label=\"CAD (PGS000018)\", color=sns.color_palette( n_colors=40, palette=\"CMRmap\" )[19], lw=8) )\n",
    "trait_handles.append( mlines.Line2D([], [], label=\"LDL (PGS000889)\", color=sns.color_palette( n_colors=40, palette=\"Dark2\" )[4], lw=8) )\n",
    "ax1.legend_.remove()\n",
    "ax2.legend( title=\"Polygenic score\", handles=trait_handles, loc=(-0.53, -0.25), shadow=False, borderpad=0.6, ncol=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra: Test interaction term **score*race**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test interaction term score*race\n",
    "\n",
    "# Standardize raw scores and calculate OR\n",
    "\n",
    "li = []\n",
    "standardize_scores = []\n",
    "logit_models_interaction_dict = {}\n",
    "models_summaries_interaction = pd.DataFrame()\n",
    "\n",
    "# Get list of panels, thresholds and GRSs used from info dictonary\n",
    "reference_panels = set( [ key.split('_')[0] for key in scores_info_dict.keys() ] )\n",
    "thresholds = set( [ key.split('_')[1] for key in scores_info_dict.keys() ] )\n",
    "grss = set( [ key.split('_')[2] for key in scores_info_dict.keys() ] )\n",
    "\n",
    "# For interaction term testing, we are testing the full cohort (whites and blacks) together. \n",
    "sea_dataset_test_interaction = sea_dataset_full\n",
    "\n",
    "# Create a dependent variable named \"Case_recoded\" based on column \"Case\", conding it as 0 and 1 to fit glm\n",
    "sea_dataset_test_interaction = sea_dataset_test_interaction.assign( Case_recoded=sea_dataset_test_interaction[\"Case\"].replace(True, 1).replace(False, 0) )\n",
    "\n",
    "for reference_panel_id in reference_panels:\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "\n",
    "        for grs in grss:\n",
    "\n",
    "            raw_score_name = \"_\".join( (reference_panel_id, threshold, grs) )\n",
    "            standardize_score_name = \"_\".join( (reference_panel_id, threshold, grs) )\n",
    "            standardize_scores.append(standardize_score_name)\n",
    "        \n",
    "            # Standardize raw scores using method scale (mean = 0 and SD = 1)\n",
    "            sea_dataset_test_interaction[ standardize_score_name ] = preprocessing.scale( sea_dataset_test_interaction[ raw_score_name ] )\n",
    "        \n",
    "            # Fit a logistic model using standardize scores testing for interaction between score and race \n",
    "            logit_models_interaction_dict[ standardize_score_name ] = sm.formula.glm(\n",
    "                # \"Case_recoded ~ \" + standardize_score_name + \"*race + age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\",\n",
    "                \"Case_recoded ~ \" + standardize_score_name + \" + race + age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\",\n",
    "                family=sm.families.Binomial(),\n",
    "                data=sea_dataset_test_interaction).fit()\n",
    "\n",
    "            # Create dictonary with scores performances\n",
    "            model_summary_series = {\n",
    "                    \"model_ref\": raw_score_name,\n",
    "                    \"reference_panel\": reference_panel_id,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"GRS\": grs,\n",
    "                    \"odds_ratio\": np.exp( logit_models_interaction_dict[ standardize_score_name ].params )[ standardize_score_name ],\n",
    "                    \"score_pvalue\": logit_models_interaction_dict[ standardize_score_name ].pvalues[ standardize_score_name ],\n",
    "                    \"conf_interval_lower\": np.exp( logit_models_interaction_dict[ standardize_score_name ].conf_int()[0][ standardize_score_name ] ),\n",
    "                    \"conf_interval_upper\": np.exp( logit_models_interaction_dict[ standardize_score_name ].conf_int()[1][ standardize_score_name ] )\n",
    "                }\n",
    "                \n",
    "            # Add metadata about the GRSs to the output\n",
    "            model_summary_series.update( pgs_metadata[grs] )\n",
    "                \n",
    "            # Transform dictionary on a pandas Series and name it as <standardize_score_name>\n",
    "            model_summary_series = pd.Series(\n",
    "                data=model_summary_series,\n",
    "                name=standardize_score_name\n",
    "            )\n",
    "                                \n",
    "            li.append(model_summary_series)\n",
    "                     \n",
    "# Concatenate results for all models tested and transpose object to make visualization easier \n",
    "models_summaries_interaction = pd.concat( li, axis=1 ).transpose().sort_values(\"odds_ratio\", ascending=False)\n",
    "\n",
    "# Move trait_mapped column to first position to facilitate analysis of excel results\n",
    "columns_order = models_summaries_interaction.columns.drop(\"trait_mapped\").tolist()\n",
    "columns_order.insert(0,\"trait_mapped\")\n",
    "models_summaries_interaction = models_summaries_interaction.reindex(columns=columns_order, copy=False)\n",
    "# models_summaries_interaction\n",
    "\n",
    "\n",
    "# List of GRS to print results\n",
    "grs_subset = [ \"PGS000018\", \"PGS000889\", \"PGS002133\", \"PGS001351\", \"PGS002161\", \"PGS000667\", \"PGS002197\", \"PGS002009\", \"PGS002026\" ]\n",
    "\n",
    "for grs_id in grs_subset:\n",
    "    full_grs_id = \"topmed_r0_\" + grs_id\n",
    "    print( \">>> \",  full_grs_id , \"\\n\", logit_models_interaction_dict[ full_grs_id ].summary(), \"\\n\")\n",
    "\n",
    "# # SIRE logist \n",
    "# grs_id = \"white_topmed_r0_PGS000018\"; print( \">>> \", grs_id, \"\\n\", logit_models_dict[ grs_id ].summary(), \"\\n\")\n",
    "# grs_id = \"black_topmed_r0_PGS000018\"; print( \">>> \", grs_id, \"\\n\", logit_models_dict[ grs_id ].summary(), \"\\n\")\n",
    "\n",
    "# # Interaction score*sire\n",
    "# grs_id = \"topmed_r0_PGS000018\"; print( \">>> \", grs_id, \"\\n\", logit_models_interaction_dict[ grs_id ].summary(), \"\\n\")\n",
    "# grs_id = \"topmed_r0_PGS000889\"; print( \">>> \", grs_id, \"\\n\", logit_models_interaction_dict[ grs_id ].summary(), \"\\n\")\n",
    "# grs_id = \"topmed_r0_PGS002133\"; print( \">>> \", grs_id, \"\\n\", logit_models_interaction_dict[ grs_id ].summary(), \"\\n\")\n",
    "# grs_id = \"topmed_r0_PGS002161\"; print( \">>> \", grs_id, \"\\n\", logit_models_interaction_dict[ grs_id ].summary(), \"\\n\")\n",
    "\n",
    "# print( logit_models_interaction_dict[ \"\" ].summary() )\n",
    "# print( logit_models_interaction_dict[ \"topmed_r0_PGS000018\" ].summary() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image resolution and background\n",
    "plt.rcParams['figure.dpi']= 150\n",
    "sns.set_style('white')\n",
    "\n",
    "# for dataset in sea_phenotypes, sea_phenotypes[sea_phenotypes[\"cr\"] > 0]: \n",
    "# for dataset in sea_phenotypes, sea_phenotypes:\n",
    "\n",
    "plot_dataset = sea_phenotypes\n",
    "# plot_dataset = sea_phenotypes[sea_phenotypes[\"cr\"] > 0]\n",
    "\n",
    "n_white = len( plot_dataset[plot_dataset[\"race\"] == \"white\"] )\n",
    "n_black = len( plot_dataset[plot_dataset[\"race\"] == \"black\"] )\n",
    "\n",
    "sns.histplot(\n",
    "       x = \"cr\",\n",
    "       data = plot_dataset,\n",
    "       hue=\"race\",\n",
    "       multiple=\"dodge\",\n",
    "       shrink=0.8,\n",
    "       # log_scale=(False,True),\n",
    "       # bins=[0,1,5,20,50,100],\n",
    "       binrange=(0,100),\n",
    "       binwidth=10\n",
    "       ).set( \n",
    "             title='Raised coronary lesions (white={0}, black={1})'.format( n_white, n_black ), \n",
    "             xlabel=\"Surface area involvement (%)\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot selected scores without segregrating cohort in whites and blacks \n",
    "\n",
    "# Set image resolution and background\n",
    "plt.rcParams['figure.dpi']= 150\n",
    "sns.set_style('white')\n",
    "\n",
    "# Function to return a subset of models that will be used on the forest plot\n",
    "def get_models_subset(reference_panel_id, grs_subset, threshold ):\n",
    "    \n",
    "    # Get only subset of lines that meet the criteria\n",
    "    models_subset = models_summaries_interaction[ (models_summaries_interaction[\"reference_panel\"] == reference_panel_id) & (models_summaries_interaction[\"GRS\"].isin( grs_subset) ) & (models_summaries_interaction[\"threshold\"] == threshold )]\n",
    "    models_subset = models_subset.sort_values(\"odds_ratio\", ascending=False)\n",
    "    \n",
    "    return( models_subset )\n",
    "\n",
    "# Define acronym and classes of selected scores\n",
    "grs_subset_and_info = {\n",
    "    \"PGS000018\": [\"CAD  \", \"CAD\"], \n",
    "    \"PGS000889\": [\" LDL  \", \"Dyslipidemia\"], \n",
    "    \"PGS002133\": [\"Fat %\", \"Adiposity\"],\n",
    "    \"PGS001351\": [\"  Ins  \", \"Dysglycemia\"], \n",
    "    # \"PGS002114\": [\"DBP\", \"Hypertension\"], \n",
    "    \"PGS002161\": [\" BMI  \", \"Adiposity\"], \n",
    "    \"PGS000667\": [\"Lp(a) \", \"Dyslipidemia\"], \n",
    "    \"PGS002197\": [\" Trig  \", \"Dyslipidemia\"], \n",
    "    \"PGS002026\": [\" T2D  \", \"Dysglycemia\"], \n",
    "    \"PGS002009\": [\" SBP  \", \"Hypertension\"]\n",
    "    }\n",
    "class_to_color = {\n",
    "    \"CAD\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[19],\n",
    "    \"Adiposity\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[32],\n",
    "    \"Dysglycemia\": sns.color_palette( n_colors=40, palette=\"CMRmap\" )[13],\n",
    "    \"Dyslipidemia\": sns.color_palette( n_colors=40, palette=\"Dark2\" )[4],\n",
    "    \"Hypertension\": sns.color_palette( n_colors=10, palette=\"Blues\" )[6]\n",
    "    }\n",
    "\n",
    "# Subset based on criterias and save to a new dataframe\n",
    "models_subset = get_models_subset( \"topmed\", grs_subset_and_info.keys(), \"r0\")\n",
    "    \n",
    "# Assign classes and colors to each score\n",
    "models_subset = models_subset.assign( acronym=[ grs_subset_and_info[ elem ][0] for elem in models_subset[\"GRS\"].to_list() ] )\n",
    "models_subset = models_subset.assign( grs_class=[ grs_subset_and_info[ elem ][1] for elem in models_subset[\"GRS\"].to_list() ] )\n",
    "models_subset = models_subset.assign( color=[ class_to_color[ elem ] for elem in models_subset[\"grs_class\"].to_list() ] )\n",
    "\n",
    "# Test p-values to see if they survive to multiple testing correction (FDR)\n",
    "fdr_result = fdrcorrection( models_subset[\"score_pvalue\"].to_list() )\n",
    "models_subset = models_subset.assign( adjusted_p=fdr_result[1] )\n",
    "models_subset = models_subset.assign( fdr_significant=fdr_result[0] )\n",
    "\n",
    "# Create plot\n",
    "p = EffectMeasurePlot(\n",
    "    label=[ \"{0}     {1}       {2:.3f}{3}\".format(row[\"GRS\"], row[\"acronym\"], row[\"score_pvalue\"], \"*\" if( row[\"fdr_significant\"] ) else \"  \" ) for index, row in models_subset.iterrows() ], \n",
    "    effect_measure=[ \"{0:.2f}\".format(row[\"odds_ratio\"]) for index, row in models_subset.iterrows() ],\n",
    "    lcl=[ \"{0:.2f}\".format(row[\"conf_interval_lower\"]) for index, row in models_subset.iterrows() ],\n",
    "    ucl=[ \"{0:.2f}\".format(row[\"conf_interval_upper\"]) for index, row in models_subset.iterrows() ]\n",
    "    )\n",
    "# Adjust axis, labels, titles and frame\n",
    "p.labels(effectmeasure='OR', scale='log')\n",
    "p.colors(pointshape=\"D\", pointcolor=models_subset[\"color\"], errorbarcolor=models_subset[\"color\"] )\n",
    "ax=p.plot(figsize=(7,3), t_adjuster=0.05, min_value=0.5, max_value=2)    \n",
    "plt.suptitle(\"     PGS ID    Trait    p-value\", x=-0.05, y=0.90, fontweight=\"bold\")\n",
    "plt.title(\"Whites+Blacks                     Odds Ratio per SD increase\", loc=\"right\",x=1.2, y=1.02)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(False)\n",
    "        \n",
    "# Add legend\n",
    "trait_handles = []\n",
    "for grs_class in sorted( set( models_subset[ \"grs_class\" ] )  ):\n",
    "    trait_handles.append( mlines.Line2D([], [], label=grs_class, color=class_to_color[grs_class], marker='_', markersize=15) )\n",
    "ax.legend(handles=trait_handles, loc=(-0.5, -0.3), shadow=False, borderpad=0.6, ncol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zepid\n",
    "# from zepid.graphics import EffectMeasurePlot\n",
    "\n",
    "# # Function to return a subset of models that will be used on the forest plot\n",
    "# def get_models_subset(race, reference_panel_id, grs_subset, threshold ):\n",
    "    \n",
    "#     # Get only subset of lines that meet the criteria\n",
    "#     models_subset = models_summaries[ (models_summaries[\"race\"] == race) & (models_summaries[\"reference_panel\"] == reference_panel_id) & (models_summaries[\"GRS\"].isin( grs_subset) ) & (models_summaries[\"threshold\"] == threshold )]\n",
    "#     models_subset = models_subset.sort_values(\"odds_ratio\", ascending=False)\n",
    "    \n",
    "#     return( models_subset )\n",
    "\n",
    "# # List of GRS to include\n",
    "# grs_subset = [ \"PGS002026\", \"PGS000889\", \"PGS002161\", \"PGS002114\", \"PGS001351\", \"PGS000018\", \"PGS002197\", \"PGS000667\", \"PGS002133\" ]\n",
    "\n",
    "# for race in ['white', \"black\"]:\n",
    "\n",
    "#     for panel in [\"topmed\", \"hrc\"]:\n",
    "\n",
    "#         # Subset based on criterias and save to a new dataframe\n",
    "#         models_subset = get_models_subset( race, panel, grs_subset, \"r0\")\n",
    "\n",
    "#         # Create plot\n",
    "#         p = EffectMeasurePlot(\n",
    "#             # label=[ \"{0}  ({1:.2e})\".format(row[\"GRS\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#             # label=[ \"{0}    {1:.2e}\".format(row[\"pgs_name\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#             label=[ \"{0}|{1}    {2:.2e}\".format(row[\"pgs_name\"], row[\"GRS\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#             effect_measure=[ \"{0:.2f}\".format(row[\"odds_ratio\"]) for index, row in models_subset.iterrows() ],\n",
    "#             lcl=[ \"{0:.2f}\".format(row[\"conf_interval_lower\"]) for index, row in models_subset.iterrows() ],\n",
    "#             ucl=[ \"{0:.2f}\".format(row[\"conf_interval_upper\"]) for index, row in models_subset.iterrows() ]\n",
    "#             )\n",
    "\n",
    "#         # Adjust axis, labels, titles and frame\n",
    "#         p.labels(effectmeasure='OR')\n",
    "#         p.colors(pointshape=\"D\")\n",
    "#         ax=p.plot(figsize=(7,3), t_adjuster=0.05, min_value=0.75, max_value=2 )\n",
    "#         # plt.suptitle(\"Polygenic Score - {0}s   p-value\".format(race), x=-0.09, y=0.98)\n",
    "#         plt.suptitle(\"Polygenic Score - {0}s ({1})   p-value\".format(race, panel), x=-0.15, y=0.98)\n",
    "#         plt.title(\"Odds Ratio per SD increase\",loc=\"center\",x=0.6, y=1.10)\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.spines['bottom'].set_visible(True)\n",
    "#         ax.spines['left'].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OLD: Plot all scores and colored by traits ###\n",
    "# #################################################\n",
    "\n",
    "# import zepid\n",
    "# from zepid.graphics import EffectMeasurePlot\n",
    "# import matplotlib.lines as mlines\n",
    "\n",
    "# # Function to return a subset of models that will be used on the forest plot\n",
    "# def get_models_subset(race, reference_panel_id, grs_subset, threshold ):\n",
    "    \n",
    "#     # Get only subset of lines that meet the criteria\n",
    "#     models_subset = models_summaries[ (models_summaries[\"race\"] == race) & (models_summaries[\"reference_panel\"] == reference_panel_id) & (models_summaries[\"GRS\"].isin( grs_subset) ) & (models_summaries[\"threshold\"] == threshold )]\n",
    "#     models_subset = models_subset.sort_values(\"odds_ratio\", ascending=False)\n",
    "    \n",
    "#     return( models_subset )\n",
    "\n",
    "# # List of GRS to include\n",
    "# # grs_subset = [ \"PGS002026\", \"PGS000889\", \"PGS002161\", \"PGS002114\", \"PGS001351\", \"PGS000018\", \"PGS002197\", \"PGS000667\", \"PGS002133\" ]\n",
    "# grs_subset = set( models_summaries[\"GRS\"].to_list() )\n",
    "\n",
    "# for race in ['white', \"black\"]:\n",
    "\n",
    "#     # Subset based on criterias and save to a new dataframe\n",
    "#     models_subset = get_models_subset( race, \"topmed\", grs_subset, \"r0\")\n",
    "    \n",
    "#     traits_set = set( models_subset[\"trait_mapped\"] )\n",
    "#     trait_2_colors = dict( zip( traits_set, sns.color_palette(n_colors=len(traits_set) ) ) )\n",
    "\n",
    "#     # Create plot\n",
    "#     p = EffectMeasurePlot(\n",
    "#         # label=[ \"{0}  {1:.2e}\".format(row[\"GRS\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#         label=[ \"{0}    {1:.2e}\".format(row[\"pgs_name\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#         effect_measure=[ \"{0:.2f}\".format(row[\"odds_ratio\"]) for index, row in models_subset.iterrows() ],\n",
    "#         lcl=[ \"{0:.2f}\".format(row[\"conf_interval_lower\"]) for index, row in models_subset.iterrows() ],\n",
    "#         ucl=[ \"{0:.2f}\".format(row[\"conf_interval_upper\"]) for index, row in models_subset.iterrows() ]\n",
    "#         )\n",
    "#     # Adjust axis, labels, titles and frame\n",
    "#     p.labels(effectmeasure='OR')\n",
    "#     p.colors(pointshape=\"D\", pointcolor=[ trait_2_colors[elem] for elem in models_subset[\"trait_mapped\"].to_list() ], errorbarcolor=[ trait_2_colors[elem] for elem in models_subset[\"trait_mapped\"].to_list() ])\n",
    "#     ax=p.plot(figsize=(7,15), t_adjuster=0.01, min_value=0.75, max_value=2 )\n",
    "    \n",
    "#     plt.suptitle(\"Polygenic Score - {0}s   p-value\".format(race), x=-0.09, y=0.90)\n",
    "#     plt.title(\"Odds Ratio per SD increase\",loc=\"center\",x=0.6, y=1.02)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['bottom'].set_visible(True)\n",
    "#     ax.spines['left'].set_visible(False)\n",
    "    \n",
    "#     # Add legend\n",
    "#     trait_handles = []\n",
    "#     for trait in sorted( trait_2_colors.keys() ):\n",
    "#         trait_handles.append( mlines.Line2D([], [], label=trait, color=trait_2_colors[trait], marker='_', markersize=15) )\n",
    "#     ax.legend(handles=trait_handles, loc=(1.65, 0.45), shadow=True, borderpad=0.6)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OLD: Plot all scores and colored by imputation reference panel ###\n",
    "# #####################################################################\n",
    "\n",
    "# import zepid\n",
    "# from zepid.graphics import EffectMeasurePlot\n",
    "# import matplotlib.lines as mlines\n",
    "\n",
    "# # Function to return a subset of models that will be used on the forest plot\n",
    "# def get_models_subset(race, grs_subset, threshold ):\n",
    "    \n",
    "#     # Get only subset of lines that meet the criteria\n",
    "#     models_subset = models_summaries[ (models_summaries[\"race\"] == race) & (models_summaries[\"GRS\"].isin( grs_subset) ) & (models_summaries[\"threshold\"] == threshold )]\n",
    "#     models_subset = models_subset.sort_values(\"odds_ratio\", ascending=False)\n",
    "    \n",
    "#     return( models_subset )\n",
    "\n",
    "# # List of GRS to include\n",
    "# # grs_subset = [ \"PGS002026\", \"PGS000889\", \"PGS002161\", \"PGS002114\", \"PGS001351\", \"PGS000018\", \"PGS002197\", \"PGS000667\", \"PGS002133\" ]\n",
    "# grs_subset = set( models_summaries[\"GRS\"].to_list() )\n",
    "\n",
    "# panel_2_colors = {\n",
    "#     'topmed': sns.color_palette(n_colors=2)[0],\n",
    "#     'hrc': sns.color_palette(n_colors=2)[1]\n",
    "# }\n",
    "\n",
    "# for race in ['white', \"black\"]:\n",
    "\n",
    "#     # Subset based on criterias and save to a new dataframe\n",
    "#     models_subset = get_models_subset( race, grs_subset, \"r0\")\n",
    "#     # Create plot\n",
    "#     p = EffectMeasurePlot(\n",
    "#         # label=[ \"{0}  ({1:.2e})\".format(row[\"GRS\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#         label=[ \"{0}    {1:.2e}\".format(row[\"pgs_name\"], row[\"score_pvalue\"]) for index, row in models_subset.iterrows() ], \n",
    "#         effect_measure=[ \"{0:.2f}\".format(row[\"odds_ratio\"]) for index, row in models_subset.iterrows() ],\n",
    "#         lcl=[ \"{0:.2f}\".format(row[\"conf_interval_lower\"]) for index, row in models_subset.iterrows() ],\n",
    "#         ucl=[ \"{0:.2f}\".format(row[\"conf_interval_upper\"]) for index, row in models_subset.iterrows() ]\n",
    "#         )\n",
    "#     # Adjust axis, labels, titles and frame\n",
    "#     p.labels(effectmeasure='OR')\n",
    "#     p.colors(pointshape=\"D\", pointcolor=[ panel_2_colors[elem] for elem in models_subset[\"reference_panel\"].to_list() ], errorbarcolor=[ panel_2_colors[elem] for elem in models_subset[\"reference_panel\"].to_list() ])\n",
    "#     ax=p.plot(figsize=(7,15), t_adjuster=0.01, min_value=0.75, max_value=2 )\n",
    "    \n",
    "#     plt.suptitle(\"Polygenic Score - {0}s   p-value\".format(race), x=-0.09, y=0.90)\n",
    "#     plt.title(\"Odds Ratio per SD\",loc=\"center\",x=0.6, y=1.02)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['bottom'].set_visible(True)\n",
    "#     ax.spines['left'].set_visible(False)\n",
    "    \n",
    "#     topmed_color = mlines.Line2D([], [], color=panel_2_colors['topmed'], marker='_', markersize=15, label='TOPMed')\n",
    "#     hrc_color = mlines.Line2D([], [], color=panel_2_colors['hrc'], marker='_', markersize=15, label='HRC')\n",
    "#     ax.legend(handles=[topmed_color, hrc_color], loc=(1.6,0.5), shadow=True, borderpad=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extra analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra 1: Plot boxplots and histograms and boxplots of raw scores spliting by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots and histograms and boxplots of raw scores spliting by sex\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "score_list = [\"wGRS49_r0\", \"wGRS49_r03\", \"wGRS49_r05\", \"wGRS49_r08\"]\n",
    "# score_list = [\"PGS000349_r0\", \"PGS000349_r03\", \"PGS000349_r05\", \"PGS000349_r08\"]\n",
    "# score_list = [\"PGS000018_r0\", \"PGS000018_r03\", \"PGS000018_r05\", \"PGS000018_r08\"]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(5*len(score_list),12))\n",
    "for i in range(0, len(score_list)):\n",
    "    sns.boxplot(\n",
    "        x = \"Case\",\n",
    "        y = score_list[i],\n",
    "        data = sea_merged_whites,\n",
    "        palette = reversed(sns.color_palette(n_colors=2)),\n",
    "        width=0.4,\n",
    "        fliersize=2,\n",
    "        ax=axs[0,i],\n",
    "    )\n",
    "    sns.histplot(\n",
    "        x = score_list[i],\n",
    "        data = sea_merged_whites[ sea_merged_whites[\"sex\"] == \"Male\" ],\n",
    "        hue=\"Case\",\n",
    "        hue_order=[True, False],\n",
    "        kde=True,\n",
    "        ax=axs[1,i]\n",
    "        ).set(title='Males (n={0})'.format( sum( sea_merged_whites[\"sex\"] == \"Male\" ) ) )\n",
    "    sns.histplot(\n",
    "        x = score_list[i],\n",
    "        data = sea_merged_whites[ sea_merged_whites[\"sex\"] == \"Female\" ],\n",
    "        hue=\"Case\",\n",
    "        hue_order=[True, False],\n",
    "        kde=True,\n",
    "        ax=axs[2,i]\n",
    "    ).set(title='Females (n={0})'.format( sum( sea_merged_whites[\"sex\"] == \"Female\" ) ) )\n",
    "\n",
    "plt.subplots_adjust(top=1.25)\n",
    "\n",
    "# # Plot only boxplots\n",
    "\n",
    "# fig, axs = plt.subplots(ncols=len(score_list), figsize=(5*len(score_list),4))\n",
    "# for i in range(0, len(score_list)):\n",
    "#     sns.boxplot(\n",
    "#         x = \"Case\",\n",
    "#         y = score_list[i],\n",
    "#         data = sea_merged_whites,\n",
    "#         hue=\"sex\",\n",
    "#         hue_order=['Male','Female'],\n",
    "#         width=0.4,\n",
    "#         fliersize=2,\n",
    "#         ax=axs[i],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra 2: Compare OR from models with 5 PCs and 10 PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to run model calculation twice (5 PCs and 10 PCs) to be able to complete the cell on this analysis\n",
    "\n",
    "# models_summaries_10pcs = models_summaries\n",
    "# models_summaries_5pcs = models_summaries\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi']= 150\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "pandas_5_10_pcs = pd.concat( [models_summaries_5pcs.add_suffix(\"_5PCs\"), models_summaries_10pcs.add_suffix(\"_10PCs\")], axis=1 )\n",
    "pandas_5_10_pcs\n",
    "\n",
    "# Create a column named race to use in plotting\n",
    "pandas_5_10_pcs[\"race\"] = pandas_5_10_pcs[\"race_5PCs\"]\n",
    "\n",
    "# Cast variables to float for plotting\n",
    "pandas_5_10_pcs = pandas_5_10_pcs.astype( {\n",
    "    \"odds_ratio_5PCs\": float,\n",
    "    \"odds_ratio_10PCs\": float,\n",
    "    \"score_pvalue_5PCs\": float\n",
    "    } )\n",
    "\n",
    "# Plot regression plot\n",
    "sns.lmplot(\n",
    "    x = \"odds_ratio_5PCs\",\n",
    "    y = \"odds_ratio_10PCs\",\n",
    "    data = pandas_5_10_pcs[ pandas_5_10_pcs[\"score_pvalue_10PCs\"] <= 0.05 ],\n",
    "    # data = pandas_5_10_pcs,\n",
    "    hue=\"race\", \n",
    "    scatter_kws={'s':50, 'alpha':0.5},\n",
    "    line_kws={'lw':2.5, 'ls': '--'}\n",
    "    )\n",
    "\n",
    "# Set x and y limits and a diagonal line\n",
    "axes_limits=(0.7, 1.6)\n",
    "plt.plot(axes_limits, axes_limits, c='black', alpha=0.8, lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra 3: Calculate and plot beta differences by R thresholds for each model, panel, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Clone models_summaries adding a new column named beta_diff\n",
    "beta_diffs = models_summaries.assign( beta_diff=np.nan )\n",
    "\n",
    "# Function to return OR value for a given model\n",
    "def get_beta_value(race, reference_panel_id, grs, threshold ):\n",
    "    \n",
    "    # Get OR value for a given model\n",
    "    or_value = models_summaries[ (models_summaries[\"race\"] == race) & (models_summaries[\"reference_panel\"] == reference_panel_id) & (models_summaries[\"GRS\"] == grs ) & (models_summaries[\"threshold\"] == threshold )][\"odds_ratio\"]\n",
    "    \n",
    "    # Transform OR to Beta\n",
    "    beta_value = math.log( or_value ) \n",
    "    \n",
    "    return( beta_value )\n",
    "\n",
    "# Loop over multiple models to get differences on betas\n",
    "for race in models_summaries['race'].unique().tolist():\n",
    "        \n",
    "    for reference_panel_id in models_summaries['reference_panel'].unique().tolist():\n",
    "        \n",
    "        for grs in models_summaries['GRS'].unique().tolist():\n",
    "            \n",
    "            # Get baseline beta (r = 0)\n",
    "            baseline_beta = get_beta_value( race, reference_panel_id, grs, \"r0\" )\n",
    "            \n",
    "            for threshold in models_summaries['threshold'].unique().tolist():\n",
    "                \n",
    "                r_beta = get_beta_value( race, reference_panel_id, grs, threshold )\n",
    "                \n",
    "                beta_diffs.loc[ \"_\".join( [race, reference_panel_id, threshold, grs] ) , \"beta_diff\"] = r_beta - baseline_beta\n",
    "                \n",
    "\n",
    "# Plot betas differences for each model | panel\n",
    "\n",
    "plt.rcParams['figure.dpi']= 100\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    beta_diffs, \n",
    "    row=\"GRS\",\n",
    "    col=\"reference_panel\",\n",
    "    sharex=False,\n",
    "    hue = \"race\",\n",
    "    hue_order=['white','black']\n",
    "    )\n",
    "\n",
    "g.map_dataframe(\n",
    "    sns.stripplot,\n",
    "    x = \"threshold\",\n",
    "    y = \"beta_diff\",\n",
    "    order = ['r0', 'r03', 'r05', 'r08']\n",
    "    )\n",
    "\n",
    "g.set_titles( col_template=\"{col_name}\", row_template=\"{row_name}\" )\n",
    "\n",
    "g.add_legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
